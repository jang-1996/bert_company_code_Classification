{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c0f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score,f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from transformers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f9bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"1. 실습용자료.txt\"\n",
    "train =  pd.read_csv(path_train,sep=\"|\",encoding='CP949')\n",
    "\n",
    "path = \"2. 모델개발용자료.txt\"\n",
    "test = pd.read_csv(path,sep=\"|\",encoding='CP949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23fc1b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d63d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(\" \", inplace = True)\n",
    "test.fillna(\" \", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e241aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-33263761baf3>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"text\"][train.index] = train[\"text_obj\"][train.index] + \" \" + train[\"text_mthd\"][train.index] + \" \" + train[\"text_deal\"][train.index]\n"
     ]
    }
   ],
   "source": [
    "train[\"text\"] = \"\"\n",
    "train[\"text\"][train.index] = train[\"text_obj\"][train.index] + \" \" + train[\"text_mthd\"][train.index] + \" \" + train[\"text_deal\"][train.index]\n",
    "test[\"text\"] = \"\"\n",
    "test[\"text\"][test.index] = test[\"text_obj\"][test.index] + \" \" + test[\"text_mthd\"][test.index] + \" \" + test[\"text_deal\"][test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "486a9683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed 고정\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "VALID_SPLIT = 0.2\n",
    "MAX_LEN=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10dce764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at bert_ckpt/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at bert_ckpt/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at bert_ckpt/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "/Users/jang-yeongdong/opt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained('bert-base-multilingual-cased',  cache_dir='bert_ckpt', do_lower_case=False)\n",
    "\n",
    "def bert_tokenizer(sent):\n",
    "    \n",
    "    encoded_dict=tokenizer.encode_plus(\n",
    "    text = sent, \n",
    "    add_special_tokens=True, \n",
    "    max_length=MAX_LEN, \n",
    "    pad_to_max_length=True, \n",
    "    return_attention_mask=True,\n",
    "    truncation = True)\n",
    "    \n",
    "    input_id=encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask']\n",
    "    token_type_id = encoded_dict['token_type_ids']\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id\n",
    "\n",
    "input_ids =[]\n",
    "attention_masks =[]\n",
    "token_type_ids =[]\n",
    "train_data_labels = []\n",
    "\n",
    "def clean_text(sent):\n",
    "    sent_clean = re.sub(\"[^가-힣ㄱ-하-ㅣ]\", \"\", sent)\n",
    "    return sent_clean\n",
    "\n",
    "for train_sent, train_label in zip(train['text'], train['digit_3']):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(clean_text(train_sent))\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        #########################################\n",
    "        train_data_labels.append(train_label)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(train_sent)\n",
    "        pass\n",
    "\n",
    "train_input_ids=np.array(input_ids, dtype=int)\n",
    "train_attention_masks=np.array(attention_masks, dtype=int)\n",
    "train_token_type_ids=np.array(token_type_ids, dtype=int)\n",
    "###########################################################\n",
    "train_inputs=(train_input_ids, train_attention_masks, train_token_type_ids)\n",
    "train_labels=np.asarray(train_data_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cb55374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at bert_ckpt/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tf_model.h5 from cache at bert_ckpt/879ba3c37de5c396bee982a9383f64cf08c9cc966d66742254a3904e6719357f.53d9b251a2a9d5d86139b64555b5e8deb0a20fc53f8a5ee958ddbb4506125a0b.h5\n",
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "class TFBertClassifier(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.classifier = tf.keras.layers.Dense(num_class, \n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range), \n",
    "                                                name=\"classifier\")\n",
    "        \n",
    "    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n",
    "        \n",
    "        #outputs 값: # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1] \n",
    "        pooled_output = self.dropout(pooled_output, training=training)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        return logits\n",
    "\n",
    "cls_model = TFBertClassifier(model_name='bert-base-multilingual-cased',\n",
    "                                  dir_path='bert_ckpt',\n",
    "                                  num_class= 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "229e242f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf2_bert_classifier -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "cls_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "model_name = \"tf2_bert_classifier\"\n",
    "\n",
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001,patience=5)\n",
    "\n",
    "checkpoint_path = os.path.join(model_name, 'weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24c5260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history 먼저 돌리고 스탑한 뒤 불러들이고 다시 학습\n",
    "cls_model.load_weights(\"/Users/jang-yeongdong/Desktop/경진대회/tf2_bert_classifier/weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8862a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "    1/12500 [..............................] - ETA: 60:45:28 - loss: 0.3314 - accuracy: 0.8750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b8bb18f94d70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 학습과 eval 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = cls_model.fit(train_inputs, train_labels, epochs=30, batch_size=64,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     validation_split = 0.2, callbacks=[earlystop_callback, cp_callback])\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습과 eval 시작\n",
    "history = cls_model.fit(train_inputs, train_labels, epochs=30, batch_size=64,\n",
    "                    validation_split = 0.2, callbacks=[earlystop_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0be9b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_id</th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0000001</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차부분정비</td>\n",
       "      <td>타이어오일교환</td>\n",
       "      <td>카센터에서 자동차부분정비 타이어오일교환</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_0000002</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>472</td>\n",
       "      <td>상점내에서</td>\n",
       "      <td>일반인을 대상으로</td>\n",
       "      <td>채소.과일판매</td>\n",
       "      <td>상점내에서 일반인을 대상으로 채소.과일판매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_0000003</td>\n",
       "      <td>G</td>\n",
       "      <td>46</td>\n",
       "      <td>467</td>\n",
       "      <td>절단하여사업체에도매</td>\n",
       "      <td>공업용고무를가지고</td>\n",
       "      <td>합성고무도매</td>\n",
       "      <td>절단하여사업체에도매 공업용고무를가지고 합성고무도매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0000004</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>475</td>\n",
       "      <td>영업점에서</td>\n",
       "      <td>일반소비자에게</td>\n",
       "      <td>열쇠잠금장치</td>\n",
       "      <td>영업점에서 일반소비자에게 열쇠잠금장치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0000005</td>\n",
       "      <td>Q</td>\n",
       "      <td>87</td>\n",
       "      <td>872</td>\n",
       "      <td>어린이집</td>\n",
       "      <td>보호자의 위탁을 받아</td>\n",
       "      <td>취학전아동보육</td>\n",
       "      <td>어린이집 보호자의 위탁을 받아 취학전아동보육</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AI_id digit_1  digit_2  digit_3    text_obj    text_mthd text_deal  \\\n",
       "0  id_0000001       S       95      952       카센터에서      자동차부분정비   타이어오일교환   \n",
       "1  id_0000002       G       47      472       상점내에서    일반인을 대상으로   채소.과일판매   \n",
       "2  id_0000003       G       46      467  절단하여사업체에도매    공업용고무를가지고    합성고무도매   \n",
       "3  id_0000004       G       47      475       영업점에서      일반소비자에게    열쇠잠금장치   \n",
       "4  id_0000005       Q       87      872        어린이집  보호자의 위탁을 받아   취학전아동보육   \n",
       "\n",
       "                          text  \n",
       "0        카센터에서 자동차부분정비 타이어오일교환  \n",
       "1      상점내에서 일반인을 대상으로 채소.과일판매  \n",
       "2  절단하여사업체에도매 공업용고무를가지고 합성고무도매  \n",
       "3         영업점에서 일반소비자에게 열쇠잠금장치  \n",
       "4     어린이집 보호자의 위탁을 받아 취학전아동보육  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a02908",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids =[]\n",
    "attention_masks =[]\n",
    "token_type_ids =[]\n",
    "train_data_labels = []\n",
    "\n",
    "def clean_text(sent):\n",
    "    sent_clean=re.sub(\"[^가-힣ㄱ-하-ㅣ]\", \" \", sent)\n",
    "    return sent_clean\n",
    "\n",
    "for test_sent in test['text']:\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(clean_text(test_sent))\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        #########################################\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(test_sent)\n",
    "        pass\n",
    "    \n",
    "test_input_ids=np.array(input_ids, dtype=int)\n",
    "test_attention_masks=np.array(attention_masks, dtype=int)\n",
    "test_token_type_ids=np.array(token_type_ids, dtype=int)\n",
    "###########################################################\n",
    "test_inputs=(test_input_ids, test_attention_masks, test_token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64e9873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cls_model.predict(test_inputs)\n",
    "# results=tf.argmax(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44372141",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=tf.argmax(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce620bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['digit_3']=results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07728061",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('bert_test_digit_3.csv',index=False,encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26a93df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test['digit_3'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3755d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in test.index:\n",
    "    test.loc[idx,'digit_2'] = str(test.loc[idx,'digit_3'])[:-1]\n",
    "    test.loc[idx,'digit_2'] = int(test.loc[idx,'digit_2'])\n",
    "    \n",
    "    if 1 <= test.loc[idx,'digit_2'] <= 3:\n",
    "        test.loc[idx,'digit_1'] = 'A'\n",
    "    elif 5 <= test.loc[idx,'digit_2'] <= 8:\n",
    "        test.loc[idx,'digit_1'] = 'B'\n",
    "    elif 10 <=test.loc[idx,'digit_2'] <= 34:\n",
    "        test.loc[idx,'digit_1'] = 'C'\n",
    "    elif test.loc[idx,'digit_2'] == 35:\n",
    "        test.loc[idx,'digit_1'] = 'D'\n",
    "    elif 36 <=test.loc[idx,'digit_2'] <= 39:\n",
    "        test.loc[idx,'digit_1'] = 'E'\n",
    "    elif 41 <=test.loc[idx,'digit_2'] <= 42:\n",
    "        test.loc[idx,'digit_1'] = 'F'\n",
    "    elif 45 <=test.loc[idx,'digit_2'] <= 47:\n",
    "        test.loc[idx,'digit_1'] = 'G'\n",
    "    elif 49 <=test.loc[idx,'digit_2'] <= 52:\n",
    "        test.loc[idx,'digit_1'] = 'H'\n",
    "    elif 55 <=test.loc[idx,'digit_2'] <= 56:\n",
    "        test.loc[idx,'digit_1'] = 'I'\n",
    "    elif 58 <=test.loc[idx,'digit_2'] <= 63:\n",
    "        test.loc[idx,'digit_1'] = 'J'\n",
    "    elif 64 <=test.loc[idx,'digit_2'] <= 66:\n",
    "        test.loc[idx,'digit_1'] = 'K'\n",
    "    elif test.loc[idx,'digit_2'] == 68:\n",
    "        test.loc[idx,'digit_1'] = 'L'\n",
    "    elif 70 <=test.loc[idx,'digit_2'] <= 73:\n",
    "        test.loc[idx,'digit_1'] = 'M'\n",
    "    elif 74 <=test.loc[idx,'digit_2'] <= 76:\n",
    "        test.loc[idx,'digit_1'] = 'N'\n",
    "    elif test.loc[idx,'digit_2'] == 84:\n",
    "        test.loc[idx,'digit_1'] = 'O'\n",
    "    elif test.loc[idx,'digit_2'] == 85:\n",
    "        test.loc[idx,'digit_1'] = 'P'\n",
    "    elif 86 <=test.loc[idx,'digit_2'] <= 87:\n",
    "        test.loc[idx,'digit_1'] = 'Q'\n",
    "    elif 90 <=test.loc[idx,'digit_2'] <= 91:\n",
    "        test.loc[idx,'digit_1'] = 'R'\n",
    "    elif 94 <=test.loc[idx,'digit_2'] <= 96:\n",
    "        test.loc[idx,'digit_1'] = 'S'\n",
    "    elif 97 <=test.loc[idx,'digit_2'] <= 98:\n",
    "        test.loc[idx,'digit_1'] = 'T'\n",
    "    elif test.loc[idx,'digit_2'] == 99:\n",
    "        test.loc[idx,'digit_1'] = 'U'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a6fd13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_id</th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000001</td>\n",
       "      <td>I</td>\n",
       "      <td>56</td>\n",
       "      <td>561</td>\n",
       "      <td>치킨전문점에서</td>\n",
       "      <td>고객의주문에의해</td>\n",
       "      <td>치킨판매</td>\n",
       "      <td>치킨전문점에서 고객의주문에의해 치킨판매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000002</td>\n",
       "      <td>G</td>\n",
       "      <td>46</td>\n",
       "      <td>466</td>\n",
       "      <td>산업공구</td>\n",
       "      <td>다른 소매업자에게</td>\n",
       "      <td>철물 수공구</td>\n",
       "      <td>산업공구 다른 소매업자에게 철물 수공구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000003</td>\n",
       "      <td>S</td>\n",
       "      <td>94</td>\n",
       "      <td>949</td>\n",
       "      <td>절에서</td>\n",
       "      <td>신도을 대상으로</td>\n",
       "      <td>불교단체운영</td>\n",
       "      <td>절에서 신도을 대상으로 불교단체운영</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_000004</td>\n",
       "      <td>C</td>\n",
       "      <td>30</td>\n",
       "      <td>302</td>\n",
       "      <td>영업장에서</td>\n",
       "      <td>고객요구로</td>\n",
       "      <td>자동차튜닝</td>\n",
       "      <td>영업장에서 고객요구로 자동차튜닝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_000005</td>\n",
       "      <td>I</td>\n",
       "      <td>56</td>\n",
       "      <td>562</td>\n",
       "      <td>실내포장마차에서</td>\n",
       "      <td>접객시설을 갖추고</td>\n",
       "      <td>소주,맥주제공</td>\n",
       "      <td>실내포장마차에서 접객시설을 갖추고 소주,맥주제공</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AI_id digit_1 digit_2  digit_3  text_obj  text_mthd text_deal  \\\n",
       "0  id_000001       I      56      561   치킨전문점에서   고객의주문에의해      치킨판매   \n",
       "1  id_000002       G      46      466      산업공구  다른 소매업자에게    철물 수공구   \n",
       "2  id_000003       S      94      949       절에서   신도을 대상으로    불교단체운영   \n",
       "3  id_000004       C      30      302     영업장에서      고객요구로     자동차튜닝   \n",
       "4  id_000005       I      56      562  실내포장마차에서  접객시설을 갖추고   소주,맥주제공   \n",
       "\n",
       "                         text  \n",
       "0       치킨전문점에서 고객의주문에의해 치킨판매  \n",
       "1       산업공구 다른 소매업자에게 철물 수공구  \n",
       "2         절에서 신도을 대상으로 불교단체운영  \n",
       "3           영업장에서 고객요구로 자동차튜닝  \n",
       "4  실내포장마차에서 접객시설을 갖추고 소주,맥주제공  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18aed15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test.csv',index=False,encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef43355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
